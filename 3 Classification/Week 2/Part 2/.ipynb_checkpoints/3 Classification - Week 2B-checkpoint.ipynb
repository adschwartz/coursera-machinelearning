{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('important_words.json', 'r') as f: # Reads the list of most frequent words\n",
    "    important_words = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Beautiful book, I love it to record cherished ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hunnt&amp;reg; Falling Flowers and Birds Kids Nurs...</td>\n",
       "      <td>Try this out for a spring project !Easy ,fun a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blessed By Pope Benedict XVI Divine Mercy Full...</td>\n",
       "      <td>very nice Divine Mercy Pendant of Jesus now on...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cloth Diaper Pins Stainless Steel Traditional ...</td>\n",
       "      <td>We bought the pins as my 6 year old Autistic s...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cloth Diaper Pins Stainless Steel Traditional ...</td>\n",
       "      <td>It has been many years since we needed diaper ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "5                          Our Baby Girl Memory Book   \n",
       "6  Hunnt&reg; Falling Flowers and Birds Kids Nurs...   \n",
       "7  Blessed By Pope Benedict XVI Divine Mercy Full...   \n",
       "8  Cloth Diaper Pins Stainless Steel Traditional ...   \n",
       "9  Cloth Diaper Pins Stainless Steel Traditional ...   \n",
       "\n",
       "                                              review  rating  sentiment  \n",
       "0  All of my kids have cried non-stop when I trie...       5          1  \n",
       "1  We wanted to get something to keep track of ou...       5          1  \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1  \n",
       "3  One of baby's first and favorite books, and it...       4          1  \n",
       "4  Very cute interactive book! My son loves this ...       5          1  \n",
       "5  Beautiful book, I love it to record cherished ...       5          1  \n",
       "6  Try this out for a spring project !Easy ,fun a...       5          1  \n",
       "7  very nice Divine Mercy Pendant of Jesus now on...       5          1  \n",
       "8  We bought the pins as my 6 year old Autistic s...       4          1  \n",
       "9  It has been many years since we needed diaper ...       5          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of positive reviews = 26579\n",
      "# of negative reviews = 26493\n"
     ]
    }
   ],
   "source": [
    "print '# of positive reviews =', len(products[products['sentiment']==1])\n",
    "print '# of negative reviews =', len(products[products['sentiment']==-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Very cute interactive book My son loves this b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Beautiful book, I love it to record cherished ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Beautiful book I love it to record cherished t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hunnt&amp;reg; Falling Flowers and Birds Kids Nurs...</td>\n",
       "      <td>Try this out for a spring project !Easy ,fun a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Try this out for a spring project Easy fun and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blessed By Pope Benedict XVI Divine Mercy Full...</td>\n",
       "      <td>very nice Divine Mercy Pendant of Jesus now on...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>very nice Divine Mercy Pendant of Jesus now on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cloth Diaper Pins Stainless Steel Traditional ...</td>\n",
       "      <td>We bought the pins as my 6 year old Autistic s...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>We bought the pins as my 6 year old Autistic s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cloth Diaper Pins Stainless Steel Traditional ...</td>\n",
       "      <td>It has been many years since we needed diaper ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>It has been many years since we needed diaper ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "5                          Our Baby Girl Memory Book   \n",
       "6  Hunnt&reg; Falling Flowers and Birds Kids Nurs...   \n",
       "7  Blessed By Pope Benedict XVI Divine Mercy Full...   \n",
       "8  Cloth Diaper Pins Stainless Steel Traditional ...   \n",
       "9  Cloth Diaper Pins Stainless Steel Traditional ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...       5          1   \n",
       "1  We wanted to get something to keep track of ou...       5          1   \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1   \n",
       "3  One of baby's first and favorite books, and it...       4          1   \n",
       "4  Very cute interactive book! My son loves this ...       5          1   \n",
       "5  Beautiful book, I love it to record cherished ...       5          1   \n",
       "6  Try this out for a spring project !Easy ,fun a...       5          1   \n",
       "7  very nice Divine Mercy Pendant of Jesus now on...       5          1   \n",
       "8  We bought the pins as my 6 year old Autistic s...       4          1   \n",
       "9  It has been many years since we needed diaper ...       5          1   \n",
       "\n",
       "                                        review_clean  \n",
       "0  All of my kids have cried nonstop when I tried...  \n",
       "1  We wanted to get something to keep track of ou...  \n",
       "2  My daughter had her 1st baby over a year ago S...  \n",
       "3  One of babys first and favorite books and it i...  \n",
       "4  Very cute interactive book My son loves this b...  \n",
       "5  Beautiful book I love it to record cherished t...  \n",
       "6  Try this out for a spring project Easy fun and...  \n",
       "7  very nice Divine Mercy Pendant of Jesus now on...  \n",
       "8  We bought the pins as my 6 year old Autistic s...  \n",
       "9  It has been many years since we needed diaper ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['contains_perfect'] = products['perfect'].apply(lambda x : 1 if x >= 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "Name: contains_perfect, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['contains_perfect'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(products['contains_perfect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import json\n",
    "\n",
    "with open('module-4-assignment-train-idx.json') as json_data:\n",
    "    train_indices = json.load(json_data)\n",
    "with open('module-4-assignment-validation-idx.json') as json_data:\n",
    "    validation_indices = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = products.iloc[train_indices]\n",
    "validation_data = products.iloc[validation_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42361, 199)\n"
     ]
    }
   ],
   "source": [
    "train_data.head(5)\n",
    "print train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42361, 199)\n"
     ]
    }
   ],
   "source": [
    "print train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features, label):\n",
    "    dataframe['constant'] = 1\n",
    "    features = ['constant'] + features\n",
    "    features_frame = dataframe[features]\n",
    "    feature_matrix = features_frame.as_matrix()\n",
    "    label_sarray = dataframe[label]\n",
    "    label_array = label_sarray.as_matrix()\n",
    "    return(feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andersschwartz/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "feature_matrix_train, sentiment_train = get_numpy_data(train_data, important_words, 'sentiment')\n",
    "feature_matrix_valid, sentiment_valid = get_numpy_data(validation_data, important_words, 'sentiment') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42361, 194)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the conditional probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "produces probablistic estimate for P(y_i = +1 | x_i, w).\n",
    "estimate ranges between 0 and 1.\n",
    "'''\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    # Take dot product of feature_matrix and coefficients  \n",
    "    score = feature_matrix.dot(coefficients)\n",
    "    \n",
    "    # Compute P(y_i = +1 | x_i, w) using the link function\n",
    "    predictions = 1 /(1 + np.exp(-score))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_predictions           = [ 0.98201379  0.26894142]\n",
      "output of predict_probability = [ 0.98201379  0.26894142]\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),          1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_predictions = np.array( [ 1./(1+np.exp(-correct_scores[0])), 1./(1+np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "print 'The following outputs must match '\n",
    "print '------------------------------------------------'\n",
    "print 'correct_predictions           =', correct_predictions\n",
    "print 'output of predict_probability =', predict_probability(dummy_feature_matrix, dummy_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the derivative of the log likelihood with L2 Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative_with_L2(errors, feature, coefficient, l2_penalty, feature_is_constant): \n",
    "    \n",
    "    # Compute the dot product of errors and feature\n",
    "    derivative = sum(feature *errors)\n",
    "\n",
    "    # add L2 penalty term for any feature that isn't the intercept.\n",
    "    if not feature_is_constant: \n",
    "        derivative -= 2*l2_penalty*coefficient\n",
    "        \n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz question: In the code above, was the intercept term regularized? No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing log likelihood with L2 Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty):\n",
    "    indicator = (sentiment==+1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    lp = np.sum((indicator-1)*scores - np.log(1. + np.exp(-scores))) - l2_penalty*np.sum(coefficients[1:]**2)\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz question: Does the term with L2 regularization increase or decrease ℓℓ(w)? Decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Ascent with L2 Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def logistic_regression_with_L2(feature_matrix, sentiment, initial_coefficients, step_size, l2_penalty, max_iter):\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    for itr in xrange(max_iter):\n",
    "        # Predict P(y_i = +1|x_1,w) using your predict_probability() function\n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "\n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "\n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = indicator - predictions\n",
    "\n",
    "        for j in xrange(len(coefficients)): # loop over each coefficient\n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j]\n",
    "            # compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "            derivative = feature_derivative_with_L2(errors, feature_matrix[:,j], coefficients[j], l2_penalty, j == 0)\n",
    "\n",
    "            # add the step size times the derivative to the current coefficient\n",
    "            coefficients[j] = coefficients[j] + (step_size*derivative)\n",
    "\n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty)\n",
    "            print 'iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp)\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix = feature_matrix_train # extracted in #7\n",
    "sentiment = sentiment_train #extracted in #7\n",
    "initial_coefficients = np.zeros(194) #a 194-dimensional vector filled with zeros\n",
    "step_size =  5e-6\n",
    "max_iter = 501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.39138303\n",
      "iteration   1: log likelihood of observed labels = -29003.71259047\n",
      "iteration   2: log likelihood of observed labels = -28834.66187288\n",
      "iteration   3: log likelihood of observed labels = -28671.70781507\n",
      "iteration   4: log likelihood of observed labels = -28514.43078198\n",
      "iteration   5: log likelihood of observed labels = -28362.48344665\n",
      "iteration   6: log likelihood of observed labels = -28215.56713122\n",
      "iteration   7: log likelihood of observed labels = -28073.41743783\n",
      "iteration   8: log likelihood of observed labels = -27935.79536396\n",
      "iteration   9: log likelihood of observed labels = -27802.48168669\n",
      "iteration  10: log likelihood of observed labels = -27673.27331484\n",
      "iteration  11: log likelihood of observed labels = -27547.98083656\n",
      "iteration  12: log likelihood of observed labels = -27426.42679977\n",
      "iteration  13: log likelihood of observed labels = -27308.44444728\n",
      "iteration  14: log likelihood of observed labels = -27193.87673876\n",
      "iteration  15: log likelihood of observed labels = -27082.57555831\n",
      "iteration  20: log likelihood of observed labels = -26570.43059938\n",
      "iteration  30: log likelihood of observed labels = -25725.48742389\n",
      "iteration  40: log likelihood of observed labels = -25055.53326910\n",
      "iteration  50: log likelihood of observed labels = -24509.63590026\n",
      "iteration  60: log likelihood of observed labels = -24054.97906083\n",
      "iteration  70: log likelihood of observed labels = -23669.51640848\n",
      "iteration  80: log likelihood of observed labels = -23337.89167628\n",
      "iteration  90: log likelihood of observed labels = -23049.07066021\n",
      "iteration 100: log likelihood of observed labels = -22794.90974921\n",
      "iteration 200: log likelihood of observed labels = -21283.29527353\n",
      "iteration 300: log likelihood of observed labels = -20570.97485473\n",
      "iteration 400: log likelihood of observed labels = -20152.21466944\n",
      "iteration 500: log likelihood of observed labels = -19876.62333410\n"
     ]
    }
   ],
   "source": [
    "coefficients_0_penalty = logistic_regression_with_L2(feature_matrix, sentiment, initial_coefficients, step_size, 0, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.39508175\n",
      "iteration   1: log likelihood of observed labels = -29003.73417180\n",
      "iteration   2: log likelihood of observed labels = -28834.71441858\n",
      "iteration   3: log likelihood of observed labels = -28671.80345068\n",
      "iteration   4: log likelihood of observed labels = -28514.58077957\n",
      "iteration   5: log likelihood of observed labels = -28362.69830317\n",
      "iteration   6: log likelihood of observed labels = -28215.85663259\n",
      "iteration   7: log likelihood of observed labels = -28073.79071393\n",
      "iteration   8: log likelihood of observed labels = -27936.26093762\n",
      "iteration   9: log likelihood of observed labels = -27803.04751805\n",
      "iteration  10: log likelihood of observed labels = -27673.94684207\n",
      "iteration  11: log likelihood of observed labels = -27548.76901327\n",
      "iteration  12: log likelihood of observed labels = -27427.33612958\n",
      "iteration  13: log likelihood of observed labels = -27309.48101569\n",
      "iteration  14: log likelihood of observed labels = -27195.04624253\n",
      "iteration  15: log likelihood of observed labels = -27083.88333261\n",
      "iteration  20: log likelihood of observed labels = -26572.49874392\n",
      "iteration  30: log likelihood of observed labels = -25729.32604153\n",
      "iteration  40: log likelihood of observed labels = -25061.34245801\n",
      "iteration  50: log likelihood of observed labels = -24517.52091982\n",
      "iteration  60: log likelihood of observed labels = -24064.99093939\n",
      "iteration  70: log likelihood of observed labels = -23681.67373669\n",
      "iteration  80: log likelihood of observed labels = -23352.19298741\n",
      "iteration  90: log likelihood of observed labels = -23065.50180166\n",
      "iteration 100: log likelihood of observed labels = -22813.44844580\n",
      "iteration 200: log likelihood of observed labels = -21321.14164794\n",
      "iteration 300: log likelihood of observed labels = -20624.98634439\n",
      "iteration 400: log likelihood of observed labels = -20219.92048845\n",
      "iteration 500: log likelihood of observed labels = -19956.11341777\n"
     ]
    }
   ],
   "source": [
    "coefficients_4_penalty = logistic_regression_with_L2(feature_matrix, sentiment, initial_coefficients, step_size, 4, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.40062984\n",
      "iteration   1: log likelihood of observed labels = -29003.76654163\n",
      "iteration   2: log likelihood of observed labels = -28834.79322654\n",
      "iteration   3: log likelihood of observed labels = -28671.94687528\n",
      "iteration   4: log likelihood of observed labels = -28514.80571589\n",
      "iteration   5: log likelihood of observed labels = -28363.02048079\n",
      "iteration   6: log likelihood of observed labels = -28216.29071186\n",
      "iteration   7: log likelihood of observed labels = -28074.35036891\n",
      "iteration   8: log likelihood of observed labels = -27936.95892966\n",
      "iteration   9: log likelihood of observed labels = -27803.89576265\n",
      "iteration  10: log likelihood of observed labels = -27674.95647005\n",
      "iteration  11: log likelihood of observed labels = -27549.95042714\n",
      "iteration  12: log likelihood of observed labels = -27428.69905549\n",
      "iteration  13: log likelihood of observed labels = -27311.03455140\n",
      "iteration  14: log likelihood of observed labels = -27196.79890162\n",
      "iteration  15: log likelihood of observed labels = -27085.84308528\n",
      "iteration  20: log likelihood of observed labels = -26575.59697506\n",
      "iteration  30: log likelihood of observed labels = -25735.07304608\n",
      "iteration  40: log likelihood of observed labels = -25070.03447306\n",
      "iteration  50: log likelihood of observed labels = -24529.31188025\n",
      "iteration  60: log likelihood of observed labels = -24079.95349572\n",
      "iteration  70: log likelihood of observed labels = -23699.83199186\n",
      "iteration  80: log likelihood of observed labels = -23373.54108747\n",
      "iteration  90: log likelihood of observed labels = -23090.01500055\n",
      "iteration 100: log likelihood of observed labels = -22841.08995135\n",
      "iteration 200: log likelihood of observed labels = -21377.25595328\n",
      "iteration 300: log likelihood of observed labels = -20704.63995428\n",
      "iteration 400: log likelihood of observed labels = -20319.25685307\n",
      "iteration 500: log likelihood of observed labels = -20072.16321721\n"
     ]
    }
   ],
   "source": [
    "coefficients_10_penalty = logistic_regression_with_L2(feature_matrix, sentiment, initial_coefficients, step_size, 10, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.48385120\n",
      "iteration   1: log likelihood of observed labels = -29004.25177457\n",
      "iteration   2: log likelihood of observed labels = -28835.97382190\n",
      "iteration   3: log likelihood of observed labels = -28674.09410083\n",
      "iteration   4: log likelihood of observed labels = -28518.17112932\n",
      "iteration   5: log likelihood of observed labels = -28367.83774654\n",
      "iteration   6: log likelihood of observed labels = -28222.77708939\n",
      "iteration   7: log likelihood of observed labels = -28082.70799392\n",
      "iteration   8: log likelihood of observed labels = -27947.37595368\n",
      "iteration   9: log likelihood of observed labels = -27816.54738615\n",
      "iteration  10: log likelihood of observed labels = -27690.00588850\n",
      "iteration  11: log likelihood of observed labels = -27567.54970126\n",
      "iteration  12: log likelihood of observed labels = -27448.98991327\n",
      "iteration  13: log likelihood of observed labels = -27334.14912742\n",
      "iteration  14: log likelihood of observed labels = -27222.86041863\n",
      "iteration  15: log likelihood of observed labels = -27114.96648229\n",
      "iteration  20: log likelihood of observed labels = -26621.50201299\n",
      "iteration  30: log likelihood of observed labels = -25819.72803950\n",
      "iteration  40: log likelihood of observed labels = -25197.34035501\n",
      "iteration  50: log likelihood of observed labels = -24701.03698195\n",
      "iteration  60: log likelihood of observed labels = -24296.66378580\n",
      "iteration  70: log likelihood of observed labels = -23961.38842316\n",
      "iteration  80: log likelihood of observed labels = -23679.38088853\n",
      "iteration  90: log likelihood of observed labels = -23439.31824267\n",
      "iteration 100: log likelihood of observed labels = -23232.88192018\n",
      "iteration 200: log likelihood of observed labels = -22133.50726528\n",
      "iteration 300: log likelihood of observed labels = -21730.03957488\n",
      "iteration 400: log likelihood of observed labels = -21545.87572145\n",
      "iteration 500: log likelihood of observed labels = -21451.95551390\n"
     ]
    }
   ],
   "source": [
    "coefficients_1e2_penalty = logistic_regression_with_L2(feature_matrix, sentiment, initial_coefficients, step_size, 1e2, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29180.31606471\n",
      "iteration   1: log likelihood of observed labels = -29009.07176112\n",
      "iteration   2: log likelihood of observed labels = -28847.62378912\n",
      "iteration   3: log likelihood of observed labels = -28695.14439397\n",
      "iteration   4: log likelihood of observed labels = -28550.95060743\n",
      "iteration   5: log likelihood of observed labels = -28414.45771129\n",
      "iteration   6: log likelihood of observed labels = -28285.15124375\n",
      "iteration   7: log likelihood of observed labels = -28162.56976044\n",
      "iteration   8: log likelihood of observed labels = -28046.29387744\n",
      "iteration   9: log likelihood of observed labels = -27935.93902900\n",
      "iteration  10: log likelihood of observed labels = -27831.15045502\n",
      "iteration  11: log likelihood of observed labels = -27731.59955260\n",
      "iteration  12: log likelihood of observed labels = -27636.98108219\n",
      "iteration  13: log likelihood of observed labels = -27547.01092670\n",
      "iteration  14: log likelihood of observed labels = -27461.42422295\n",
      "iteration  15: log likelihood of observed labels = -27379.97375625\n",
      "iteration  20: log likelihood of observed labels = -27027.18208317\n",
      "iteration  30: log likelihood of observed labels = -26527.22737267\n",
      "iteration  40: log likelihood of observed labels = -26206.59048765\n",
      "iteration  50: log likelihood of observed labels = -25995.96903148\n",
      "iteration  60: log likelihood of observed labels = -25854.95710284\n",
      "iteration  70: log likelihood of observed labels = -25759.08109950\n",
      "iteration  80: log likelihood of observed labels = -25693.05688014\n",
      "iteration  90: log likelihood of observed labels = -25647.09929349\n",
      "iteration 100: log likelihood of observed labels = -25614.81468705\n",
      "iteration 200: log likelihood of observed labels = -25536.20998919\n",
      "iteration 300: log likelihood of observed labels = -25532.57691220\n",
      "iteration 400: log likelihood of observed labels = -25532.35543765\n",
      "iteration 500: log likelihood of observed labels = -25532.33970049\n"
     ]
    }
   ],
   "source": [
    "coefficients_1e3_penalty = logistic_regression_with_L2(feature_matrix, sentiment, initial_coefficients, step_size, 1e3, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29271.85955115\n",
      "iteration   1: log likelihood of observed labels = -29271.71006589\n",
      "iteration   2: log likelihood of observed labels = -29271.65738833\n",
      "iteration   3: log likelihood of observed labels = -29271.61189923\n",
      "iteration   4: log likelihood of observed labels = -29271.57079975\n",
      "iteration   5: log likelihood of observed labels = -29271.53358505\n",
      "iteration   6: log likelihood of observed labels = -29271.49988440\n",
      "iteration   7: log likelihood of observed labels = -29271.46936584\n",
      "iteration   8: log likelihood of observed labels = -29271.44172890\n",
      "iteration   9: log likelihood of observed labels = -29271.41670149\n",
      "iteration  10: log likelihood of observed labels = -29271.39403722\n",
      "iteration  11: log likelihood of observed labels = -29271.37351294\n",
      "iteration  12: log likelihood of observed labels = -29271.35492661\n",
      "iteration  13: log likelihood of observed labels = -29271.33809523\n",
      "iteration  14: log likelihood of observed labels = -29271.32285309\n",
      "iteration  15: log likelihood of observed labels = -29271.30905015\n",
      "iteration  20: log likelihood of observed labels = -29271.25729150\n",
      "iteration  30: log likelihood of observed labels = -29271.20657205\n",
      "iteration  40: log likelihood of observed labels = -29271.18775997\n",
      "iteration  50: log likelihood of observed labels = -29271.18078247\n",
      "iteration  60: log likelihood of observed labels = -29271.17819447\n",
      "iteration  70: log likelihood of observed labels = -29271.17723457\n",
      "iteration  80: log likelihood of observed labels = -29271.17687853\n",
      "iteration  90: log likelihood of observed labels = -29271.17674648\n",
      "iteration 100: log likelihood of observed labels = -29271.17669750\n",
      "iteration 200: log likelihood of observed labels = -29271.17666862\n",
      "iteration 300: log likelihood of observed labels = -29271.17666862\n",
      "iteration 400: log likelihood of observed labels = -29271.17666862\n",
      "iteration 500: log likelihood of observed labels = -29271.17666862\n"
     ]
    }
   ],
   "source": [
    "coefficients_1e5_penalty = logistic_regression_with_L2(feature_matrix, sentiment, initial_coefficients, step_size, 1e5, max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which words contribute most to positive & negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love', 'loves', 'easy', 'perfect', 'great']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients_0_penalty_nointercept = list(coefficients_0_penalty[1:]) # exclude intercept\n",
    "word_coefficient_tuples = [(word, coefficient) for word, coefficient in zip(important_words, coefficients_0_penalty_nointercept)]\n",
    "word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=True)\n",
    "word_coefficient_tuples\n",
    "positive_words = [str(i[0]) for i in word_coefficient_tuples[:5]]\n",
    "positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disappointed', 'money', 'return', 'waste', 'returned']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1])\n",
    "negative_words = [str(i[0]) for i in negative_word_coefficient_tuples[:5]]\n",
    "negative_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effects of increasing L2 on the 10 pos and neg words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named graphlab",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-c910cf78b3f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphlab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'(intercept)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimportant_words\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_coefficients_to_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named graphlab"
     ]
    }
   ],
   "source": [
    "import graphlab\n",
    "table = graphlab.SFrame({'word': ['(intercept)'] + important_words})\n",
    "def add_coefficients_to_table(coefficients, column_name):\n",
    "    table[column_name] = coefficients\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'add_coefficients_to_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-6ba7ab5c4645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madd_coefficients_to_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefficients_0_penalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coefficients [L2=0]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0madd_coefficients_to_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefficients_4_penalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coefficients [L2=4]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0madd_coefficients_to_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefficients_10_penalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coefficients [L2=10]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0madd_coefficients_to_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefficients_1e2_penalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coefficients [L2=1e2]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0madd_coefficients_to_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefficients_1e3_penalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coefficients [L2=1e3]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'add_coefficients_to_table' is not defined"
     ]
    }
   ],
   "source": [
    "add_coefficients_to_table(coefficients_0_penalty, 'coefficients [L2=0]')\n",
    "add_coefficients_to_table(coefficients_4_penalty, 'coefficients [L2=4]')\n",
    "add_coefficients_to_table(coefficients_10_penalty, 'coefficients [L2=10]')\n",
    "add_coefficients_to_table(coefficients_1e2_penalty, 'coefficients [L2=1e2]')\n",
    "add_coefficients_to_table(coefficients_1e3_penalty, 'coefficients [L2=1e3]')\n",
    "add_coefficients_to_table(coefficients_1e5_penalty, 'coefficients [L2=1e5]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "\n",
    "def make_coefficient_plot(table, positive_words, negative_words, l2_penalty_list):\n",
    "    cmap_positive = plt.get_cmap('Reds')\n",
    "    cmap_negative = plt.get_cmap('Blues')\n",
    "    \n",
    "    xx = l2_penalty_list\n",
    "    plt.plot(xx, [0.]*len(xx), '--', lw=1, color='k')\n",
    "    \n",
    "    table_positive_words = table[table['word'].isin(positive_words)]\n",
    "    table_negative_words = table[table['word'].isin(negative_words)]\n",
    "    del table_positive_words['word']\n",
    "    del table_negative_words['word']\n",
    "    \n",
    "    for i in xrange(len(positive_words)):\n",
    "        color = cmap_positive(0.8*((i+1)/(len(positive_words)*1.2)+0.15))\n",
    "        plt.plot(xx, table_positive_words[i:i+1].as_matrix().flatten(),\n",
    "                 '-', label=positive_words[i], linewidth=4.0, color=color)\n",
    "        \n",
    "    for i in xrange(len(negative_words)):\n",
    "        color = cmap_negative(0.8*((i+1)/(len(negative_words)*1.2)+0.15))\n",
    "        plt.plot(xx, table_negative_words[i:i+1].as_matrix().flatten(),\n",
    "                 '-', label=negative_words[i], linewidth=4.0, color=color)\n",
    "        \n",
    "    plt.legend(loc='best', ncol=3, prop={'size':16}, columnspacing=0.5)\n",
    "    plt.axis([1, 1e5, -1, 2])\n",
    "    plt.title('Coefficient path')\n",
    "    plt.xlabel('L2 penalty ($\\lambda$)')\n",
    "    plt.ylabel('Coefficient value')\n",
    "    plt.xscale('log')\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "make_coefficient_plot(table, positive_words, negative_words, l2_penalty_list=[0, 4, 10, 1e2, 1e3, 1e5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(feature_matrix, sentiment, coefficients):\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    apply_threshold = np.vectorize(lambda x: 1. if x > 0  else -1.)\n",
    "    predictions = apply_threshold(scores)\n",
    "    \n",
    "    num_correct = (predictions == sentiment).sum()\n",
    "    accuracy = num_correct*1.0 / len(feature_matrix)    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = {}\n",
    "train_accuracy[0]   = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_0_penalty)\n",
    "train_accuracy[4]   = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_4_penalty)\n",
    "train_accuracy[10]  = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_10_penalty)\n",
    "train_accuracy[1e2] = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_1e2_penalty)\n",
    "train_accuracy[1e3] = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_1e3_penalty)\n",
    "train_accuracy[1e5] = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_1e5_penalty)\n",
    "\n",
    "validation_accuracy = {}\n",
    "validation_accuracy[0]   = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_0_penalty)\n",
    "validation_accuracy[4]   = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_4_penalty)\n",
    "validation_accuracy[10]  = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_10_penalty)\n",
    "validation_accuracy[1e2] = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_1e2_penalty)\n",
    "validation_accuracy[1e3] = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_1e3_penalty)\n",
    "validation_accuracy[1e5] = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_1e5_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 penalty = 0\n",
      "train accuracy = 0.785156157787, validation_accuracy = 0.78143964149\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 4\n",
      "train accuracy = 0.785108944548, validation_accuracy = 0.781533003454\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 10\n",
      "train accuracy = 0.784990911452, validation_accuracy = 0.781719727383\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 100\n",
      "train accuracy = 0.783975826822, validation_accuracy = 0.781066193633\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 1000\n",
      "train accuracy = 0.775855149784, validation_accuracy = 0.771356549342\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 100000\n",
      "train accuracy = 0.680366374731, validation_accuracy = 0.667818130893\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Build a simple report\n",
    "for key in sorted(validation_accuracy.keys()):\n",
    "    print \"L2 penalty = %g\" % key\n",
    "    print \"train accuracy = %s, validation_accuracy = %s\" % (train_accuracy[key], validation_accuracy[key])\n",
    "    print \"--------------------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.tight_layout>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAFtCAYAAABcCP1ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naSIiIiIJSCFNREREJAH9Px4kXb9m0+E3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111e62810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optional. Plot accuracy on training and validation sets over choice of L2 penalty.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "\n",
    "sorted_list = sorted(train_accuracy.items(), key=lambda x:x[0])\n",
    "plt.plot([p[0] for p in sorted_list], [p[1] for p in sorted_list], 'bo-', linewidth=4, label='Training accuracy')\n",
    "sorted_list = sorted(validation_accuracy.items(), key=lambda x:x[0])\n",
    "plt.plot([p[0] for p in sorted_list], [p[1] for p in sorted_list], 'ro-', linewidth=4, label='Validation accuracy')\n",
    "plt.xscale('symlog')\n",
    "plt.axis([0, 1e3, 0.78, 0.786])\n",
    "plt.legend(loc='lower left')\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
